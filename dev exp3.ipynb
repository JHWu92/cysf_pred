{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dtm\n",
    "from src.experiment_based_function import *\n",
    "from wKit.utility.file_sys import mkdirs_if_not_exist\n",
    "from wKit.ML.sk_ml import grid_cv_a_model, grid_cv_default_params, evaluator_scalable_cls, show_important_features, confusion_matrix_as_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    y = pd.read_csv('data/y_csl_all.csv', index_col=0).csl\n",
    "    X_total = pd.read_csv('data/x_TOTAL_~2014.csv', index_col=0)\n",
    "    X_type = pd.read_csv('data/x_NO_TOTAL_~2014.csv', index_col=0)\n",
    "    Xs = {'NO_TOTAL': X_type, 'TOTAL': X_total}\n",
    "    return Xs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model_params(name):\n",
    "    params = grid_cv_default_params()\n",
    "    if name == 'XGBreg': \n",
    "        model = xgboost.XGBRegressor()\n",
    "        param = params['reg']['XGBreg']\n",
    "    elif name == 'XGBcls': \n",
    "        model = xgboost.XGBClassifier()\n",
    "        param = params['cls']['XGBcls']\n",
    "    elif name == 'GDBcls': \n",
    "        model = GradientBoostingClassifier()\n",
    "        param = params['cls']['GDBcls']\n",
    "    else: raise('no model')\n",
    "        \n",
    "    return model, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def upsample_one_class(y_one_class, target_num):\n",
    "    num = len(y_one_class)\n",
    "    factor = int(round(target_num/num))\n",
    "    if factor == 1:  # don't do anything\n",
    "        return y_one_class\n",
    "    return pd.concat([y_one_class]*factor)  # dulicating by factor times\n",
    "\n",
    "def upsample(train_y):\n",
    "    max_ = train_y.round().value_counts().max()\n",
    "    labels = train_y.round().unique()\n",
    "    uped = []\n",
    "    for label in labels:\n",
    "        y_one_class = train_y[train_y.round()==label]\n",
    "        up = upsample_one_class(y_one_class, max_)\n",
    "        uped.append(up)\n",
    "    return pd.concat(uped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_total_or_type(total_or_not):\n",
    "    return {'TOTAL': 'total', 'NO_TOTAL': 'type'}[total_or_not]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combo = [('TOTAL', 'XGBcls'), ('NO_TOTAL', 'XGBreg'), ('TOTAL', 'GDBcls')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in SEEDS:\n",
    "    # set up experiment path\n",
    "    exp_path = 'data/up_down_experiment/seed_%d' % seed\n",
    "    upsample_path = '%s/upsample_res' % exp_path\n",
    "    mkdirs_if_not_exist(exp_path)\n",
    "    mkdirs_if_not_exist(upsample_path)\n",
    "    \n",
    "    # get train/test index\n",
    "    idx_fn = '%s/%s' % (exp_path, 'indices.txt')\n",
    "    train_idx, test_idx = get_idx(y.index, idx_fn, seed)\n",
    "    \n",
    "    # get upsampled train_y and origin test_y\n",
    "    train_y, test_y = y.loc[train_idx], y.loc[test_idx]\n",
    "    uped_train_y = upsample(train_y)\n",
    "    \n",
    "    # store result\n",
    "    df_grid_res, df_eval_res = [], []\n",
    "    \n",
    "    # iterate combo\n",
    "    for total_or_not, name in combo:\n",
    "        total_or_type = get_total_or_type(total_or_not)\n",
    "        \n",
    "        # get upsampled train x and origin test_x\n",
    "        X = Xs[total_or_not]\n",
    "        uped_train_x = X.loc[uped_train_y.index]\n",
    "        test_x = X.loc[test_idx]\n",
    "        feature_names = uped_train_x.columns\n",
    "        uped_train_x, test_x = scale_ftr(uped_train_x, test_x)\n",
    "        # grid search best fit model\n",
    "        model, param = init_model_params(name)\n",
    "        grid_res = grid_cv_a_model(uped_train_x, uped_train_y, model, param, kind=name[-3:], name=name, path=upsample_path)\n",
    "        grid_res['total_or_type'] = total_or_type\n",
    "        model = grid_res.pop('best_model')\n",
    "        df_grid_res.append(grid_res)\n",
    "        # evaluate on original test set\n",
    "        eval_res = evaluator_scalable_cls(model, uped_train_x, uped_train_y, test_x, test_y)\n",
    "        eval_res['total_or_type'] = total_or_type\n",
    "        eval_res['model_name'] = name\n",
    "        df_eval_res.append(eval_res)\n",
    "        # save feature importances \n",
    "        imp = show_important_features(model, labels=feature_names, set_std=False, show_plt=False).drop('std', axis=1) \n",
    "        imp.columns = ['label', 'importance_%d' % seed]\n",
    "        imp.to_csv('%s/imp-%s-%s.csv' % (upsample_path, name, total_or_not))\n",
    "        # save confusion matrix\n",
    "        cfsn_norm = confusion_matrix_as_df(model, test_x, test_y, labels=[1, 2, 3, 4, 5], normalize=True)\n",
    "        cfsn_norm.to_csv('%s/cfsn_norm-%s-%s.csv' % (upsample_path, name, total_or_not))\n",
    "        cfsn = confusion_matrix_as_df(model, test_x, test_y, labels=[1, 2, 3, 4, 5])\n",
    "        cfsn.to_csv('%s/cfsn-%s-%s.csv' % (upsample_path, name, total_or_not))\n",
    "        break\n",
    "    \n",
    "    # save result\n",
    "    df_grid_res = pd.DataFrame(df_grid_res)\n",
    "    df_grid_res.to_csv('%s/grid_res.csv' % upsample_path)\n",
    "    df_eval_res = pd.DataFrame(df_eval_res)\n",
    "    df_eval_res.to_csv('%s/eval_res.csv' % upsample_path)\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
