{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wKit.utility.file_sys import mkdirs_if_not_exist\n",
    "from wKit.ML.scaler import minmax, max_cutoff\n",
    "from wKit.ML.feature_selection import fselect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.constants import dir_data, fn_target_lts_dc, fn_features_dc\n",
    "from src.ftr_aggregate import load_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wKit.ML.sk_ml import sk_models, grid_cv_default_params, grid_cv_models, evaluate_grid_cv, evaluator_scalable_cls, model_order_by_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_cut_cols(cols_by_type):\n",
    "    max_cutoff_candidates = ['crash', '311', 'poi', 'crime', 'v0', 'moving', 'parking']\n",
    "    max_cut_cols = []\n",
    "    for c in max_cutoff_candidates:\n",
    "        max_cut_cols += cols_by_type[c]\n",
    "    return max_cut_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idx(lts, idx_fn, seed):\n",
    "    if not os.path.exists(idx_fn):\n",
    "        train_idx, test_idx = train_test_split(lts.index, test_size=0.2, random_state=seed)\n",
    "        with open(idx_fn, 'w') as f:\n",
    "            f.write('train\\t%s\\n' % ','.join(train_idx.astype(str).tolist()))\n",
    "            f.write('test\\t%s\\n' % ','.join(test_idx.astype(str).tolist()))\n",
    "    else:\n",
    "        with open(idx_fn) as f:\n",
    "            lines = f.readlines()\n",
    "            train_idx = lines[0].strip().split('\\t')[1].split(',')\n",
    "            train_idx = [int(x) for x in train_idx]\n",
    "            test_idx = lines[1].strip().split('\\t')[1].split(',')\n",
    "            test_idx = [int(x) for x in test_idx]\n",
    "    return train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def scale_ftr(train_x, test_x, max_cut_cols=None):\n",
    "    if max_cut_cols is not None:\n",
    "        print('for', max_cut_cols[:5], '...', len(\n",
    "            max_cut_cols), 'cols, do a max cut off with max=1000, alpha=0.75 first, then min max scale to [0,1]')\n",
    "        for col in max_cut_cols:\n",
    "            train_x[col] = max_cutoff(train_x[col], max_=1000)\n",
    "            test_x[col] = max_cutoff(test_x[col], max_=1000)\n",
    "    else:\n",
    "        print('min max only to [0,1]')\n",
    "    scaler = minmax()\n",
    "    scaler.fit(train_x)\n",
    "    train_x = scaler.transform(train_x)\n",
    "    test_x = scaler.transform(test_x)\n",
    "\n",
    "    return train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def scale_and_selection(train_x, train_y, test_x, test_y, selection_type, max_cut=True, **kwargs):\n",
    "\n",
    "    print('scale features')\n",
    "    train_x, test_x = scale_ftr(train_x, test_x, max_cut_cols) if max_cut else scale_ftr(train_x, test_x)\n",
    "\n",
    "    print('feature selection, choice:', selection_type)\n",
    "    selected_ftr = None\n",
    "    selected_ftr = fselect(train_x, train_y, selection_type, **kwargs) if selection_type != 'None' else np.array([True] * train_x.shape[1])\n",
    "\n",
    "    if selected_ftr is None:\n",
    "        print('!!!!! =============== selected feature is None =============== !!!!! ')\n",
    "\n",
    "    train_x = train_x[:, selected_ftr]\n",
    "    test_x = test_x[:, selected_ftr]\n",
    "    return {'train_x' : train_x, 'train_y': train_y, 'test_x': test_x, 'test_y': test_y, 'selected_ftr': selected_ftr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def write_ftr_names(cv_dir, ftr_name, selected):\n",
    "\n",
    "    keeps = np.array(ftr_name)[selected]\n",
    "    removes = np.array(ftr_name)[~selected]\n",
    "    with open(os.path.join(cv_dir, 'feature_names.txt'), 'w') as f:\n",
    "        f.write('all\\t%d' % len(ftr_name) + '\\t' + ', '.join(ftr_name) + '\\n')\n",
    "        f.write('keeps\\t%d' % len(keeps) + '\\t' + ', '.join(keeps) + '\\n')\n",
    "        f.write('removes\\t%d' % len(removes) + '\\t' + ', '.join(removes) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_eval(ds, cv_dir, ftr_name):\n",
    "    train_x, train_y, test_x, test_y, selected_ftr = ds['train_x'], ds['train_y'], ds['test_x'], ds['test_y'], ds['selected_ftr']\n",
    "    write_ftr_names(cv_dir, ftr_name, selected_ftr)\n",
    "\n",
    "    print('get models and grid_cv tuning parameters')\n",
    "    models = sk_models(stoplist=())\n",
    "#     order = [['cls', ['RFcls', 'BAGcls', 'GDBcls']]]\n",
    "    order = model_order_by_speed(speed=1)\n",
    "    params = grid_cv_default_params()\n",
    "\n",
    "    print('running grid cv')\n",
    "    df_cv_res = grid_cv_models(train_x, train_y, models, params, order=order, path=cv_dir, verbose=True)\n",
    "    print('saved grid cv result for each model')\n",
    "\n",
    "    print('evaluating best model of each kind')\n",
    "    df_eval = evaluate_grid_cv(df_cv_res, train_x, train_y, test_x, test_y, evaluator_scalable_cls, path=cv_dir)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugr = pd.read_csv(dir_data + 'y_ugr_all.csv', index_col=0)\n",
    "totals = ['NO_TOTAL', 'TOTAL']\n",
    "years_choices = [('~2014', (2014, 2015, 2016, 2017)), ('~2016', (2016, 2017)), ]\n",
    "features = {}\n",
    "for total_or_not in totals:\n",
    "    for year_type, years in years_choices:\n",
    "        ftrs,cols_by_type = load_features(ugr, how=total_or_not, years=years, y_column_name='ugr')   \n",
    "        features[(total_or_not, year_type)] = (ftrs, cols_by_type)\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "ys = ugr.ugr\n",
    "ys = ys.apply(round)\n",
    "target_index_seg = ys.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for seed in [0, 100, 972, 5258, 7821, 40918, 57852, 168352, 291592, 789729423]:\n",
    "\n",
    "    exp_path = 'data/ugr_experiment/seed_%d' % seed\n",
    "    mkdirs_if_not_exist(exp_path)\n",
    "    print(dtm.now(), 'experiment top dir =', exp_path)\n",
    "\n",
    "    idx_fn = '%s/%s' % (exp_path, 'indices.txt')\n",
    "    train_idx, test_idx = get_idx(ys, idx_fn, seed)\n",
    "\n",
    "    print('split train and test')\n",
    "\n",
    "    for total_or_not in ['NO_TOTAL', 'TOTAL']:\n",
    "        for year_type, years in [('~2014', (2014, 2015, 2016, 2017)), ('~2016', (2016, 2017)), ]:\n",
    "\n",
    "            print(dtm.now(), 'loading features', total_or_not, year_type)\n",
    "            ftrs, cols_by_type = features[(total_or_not, year_type)]\n",
    "            train_x, train_y = ftrs.loc[train_idx], ys.loc[train_idx]\n",
    "            test_x, test_y = ftrs.loc[test_idx], ys.loc[test_idx]\n",
    "            ftr_name = train_x.columns\n",
    "\n",
    "            max_cut_cols = get_max_cut_cols(cols_by_type)\n",
    "\n",
    "            for max_cut in (True, False,):\n",
    "                for selection_type in ['None', 'rfecv_linsvc', 'mrmr']:\n",
    "                    exp_param = '#'.join(\n",
    "                        [total_or_not, year_type, 'max_cut' if max_cut else 'minmax_only', selection_type])\n",
    "                    exp_param_path = '%s/%s' % (exp_path, exp_param)\n",
    "                    mkdirs_if_not_exist(exp_param_path)\n",
    "                    print(dtm.now(), 'experiment with', exp_param)\n",
    "                    gridcv_ready = scale_and_selection(train_x, train_y, test_x, test_y, selection_type, max_cut)\n",
    "                    grid_eval(gridcv_ready, exp_param_path, ftr_name)\n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
