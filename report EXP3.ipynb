{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best 3 solutions based on EXP1 in turns of f1 weighted is:\n",
    "# XGBcls, RoadNet+Segment TOTAL, 0.5284741533025521\n",
    "# XGBreg, RoadNet+Segment NO_TOTAL, 0.541270\n",
    "# GDBcls, RoadNet+Segment TOTAL, 0.5107103184755486\n",
    "# with ~2014, min-max, no feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.experiment_based_function import SEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(upsample_type, eval_or_grid):\n",
    "    res = []\n",
    "\n",
    "    for smote_kind in ['regular', 'svm']:\n",
    "        for seed in SEEDS:\n",
    "            exp_path = 'data/up_down_experiment/seed_%d' % seed\n",
    "            smote_path = '%s/%s_%s' % (exp_path, upsample_type, smote_kind)\n",
    "            try:\n",
    "                df = pd.read_csv('%s/%s_res.csv' % (smote_path, eval_or_grid), index_col=0)\n",
    "                df['seed'] = seed\n",
    "                df['smote_kind'] = smote_kind\n",
    "                res.append(df)\n",
    "            except FileNotFoundError:\n",
    "                print('no %s_res in' % eval_or_grid, smote_path)\n",
    "\n",
    "    res = pd.concat(res, ignore_index=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_choices = ['test_f1_weighted', 'test_f1_macro', 'test_f1_micro']\n",
    "keys = ['smote_kind', 'model_name', 'feature_selection']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smote on train only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation on origin test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "on_train_eval_res = get_result('upsample_smote', 'eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "on_train_eval_res[['up_y_dist', 'y_dist']].iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = on_train_eval_res.groupby(keys).mean()[f1_choices]\n",
    "stds = on_train_eval_res.groupby(keys).std()[f1_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_choices = ['test_f1_weighted', 'test_f1_macro', 'test_f1_micro']\n",
    "keys = ['smote_kind', 'model_name', 'feature_selection']\n",
    "means = on_train_eval_res.groupby(keys).mean()[f1_choices]\n",
    "stds = on_train_eval_res.groupby(keys).std()[f1_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_type = f1_choices[0]\n",
    "print('f1_type =', f1_type)\n",
    "\n",
    "means_to_plot = means[[f1_type]].sort_values(f1_type, ascending=True)\n",
    "stds_to_plot = stds[[f1_type]]\n",
    "\n",
    "means_to_plot.plot(kind='barh', figsize=(10,7), xerr=stds_to_plot)\n",
    "means_to_plot.iloc[:-3:-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV mean test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "on_train_grid_res = get_result('upsample_smote', 'grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "on_train_grid_res[on_train_grid_res['kind']=='cls'].groupby(keys).mean()[['mean_test']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smote on whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation on smoted test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "on_all_eval_res = get_result('upsample_smote_onall', 'eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = on_all_eval_res.groupby(keys).mean()[f1_choices]\n",
    "stds = on_all_eval_res.groupby(keys).std()[f1_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_type = f1_choices[0]\n",
    "print('f1_type =', f1_type)\n",
    "\n",
    "means_to_plot = means[[f1_type]].sort_values(f1_type, ascending=True)\n",
    "stds_to_plot = stds[[f1_type]]\n",
    "\n",
    "means_to_plot.plot(kind='barh', figsize=(10,7), xerr=stds_to_plot)\n",
    "means_to_plot.iloc[:-3:-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV mean test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "on_all_grid_res = get_result('upsample_smote_onall', 'grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "on_all_grid_res[on_all_grid_res['kind']=='cls'].groupby(keys).mean()[['mean_test']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_exp(eval_or_grid):\n",
    "    res = []\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        exp_path = 'data/up_down_experiment/seed_%d' % seed\n",
    "        upsample_path = '%s/upsample_naive' % (exp_path)\n",
    "        try:\n",
    "            df = pd.read_csv('%s/%s_res.csv' % (upsample_path, eval_or_grid), index_col=0)\n",
    "            df['seed'] = seed\n",
    "            res.append(df)\n",
    "        except FileNotFoundError:\n",
    "            print('no %s_res in' % eval_or_grid, upsample_path)\n",
    "\n",
    "    res = pd.concat(res, ignore_index=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_eval_res = naive_exp('eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = naive_eval_res.groupby(keys[1:]).mean()[f1_choices]\n",
    "stds = naive_eval_res.groupby(keys[1:]).std()[f1_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_type = f1_choices[0]\n",
    "print('f1_type =', f1_type)\n",
    "\n",
    "means_to_plot = means[[f1_type]].sort_values(f1_type, ascending=True)\n",
    "stds_to_plot = stds[[f1_type]]\n",
    "\n",
    "means_to_plot.plot(kind='barh', figsize=(10,7), xerr=stds_to_plot)\n",
    "means_to_plot.iloc[:-3:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
